(window.webpackJsonp=window.webpackJsonp||[]).push([[371],{1229:function(a,t,s){"use strict";s.r(t);var n=s(15),e=Object(n.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"最终的一致"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#最终的一致"}},[a._v("#")]),a._v(" 最终的一致")]),a._v(" "),s("p",[a._v("在我看来，最终一致性是说，系统中所有的数据副本在经过一段时间的同步后，最终能够达到一个一致的状态。也就是说，在数据一致性上，存在一个短暂的延迟。强一致性可以看作是不存在延迟的一致性。")]),a._v(" "),s("p",[a._v("那实现最终一致性的具体方式是什么呢?常用的有这样几种：")]),a._v(" "),s("ul",[s("li",[s("p",[a._v("读时修复:在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。")])]),a._v(" "),s("li",[s("p",[a._v("写时修复:在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。")])]),a._v(" "),s("li",[s("p",[a._v("异步修复:这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。")])])]),a._v(" "),s("p",[a._v("在这里，我想强调的是因为写时修复不需要做数据一致性对比，性能消耗比较低，对系统运行影响也不大，所以我推荐你在实现最终一致性时优先实现这种方式。而读时修复和异步修复因为需要做数据的一致性对比，性能消耗比较多。")])])}),[],!1,null,null,null);t.default=e.exports}}]);