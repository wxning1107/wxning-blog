# 简述 TCP 的 TIME_WAIT 和 CLOSE_WAIT

<font size=5>**TIME_WAIT**</font>


TCP要保证在所有可能的情况下使得所有的数据都能够被正确送达。当你关闭一个socket时，主动关闭一端的socket将进入TIME_WAIT状 态，而被动关闭一方则转入CLOSED状态，这的确能够保证所有的数据都被传输。当一个socket关闭的时候，是通过两端四次握手完成的，当一端调用 close()时，就说明本端没有数据要发送了。这好似看来在握手完成以后，socket就都可以处于初始的CLOSED状态了，其实不然。原因是这样安 排状态有两个问题， 首先，我们没有任何机制保证最后的一个ACK能够正常传输，第二，网络上仍然有可能有残余的数据包(wandering duplicates)，我们也必须能够正常处理。

::: tip 为什么要有TIME_WAIT？
原因一：假设最后的一个ACK丢失，那么被动关闭一方收不到这最后一个ACK则会重发FIN。此时主动关闭一方必须保持一个有效的(time_wait状态下维持)状态信息，以便可以重发ACK。如果主动关闭的socket不维持这种状态而是进入close状态，那么主动关闭的一方在收到被动关闭方重新发送的FIN时则响应给被动方一个RST。被动方收到这个RST后会认为此次回话出错了。这就是为什么在socket在关闭后，任然处于time_wait状态的第一个原因。因为他要等待可能出现的错误(被动关闭端没有接收到最后一个ACK)，以便重发ACK。

原因二：假设目前连接的通信双方都调用了close(),双方同时进入closed的终结状态，而没有走time_wait状态。则会出现如下问题：假如现在有一个新的连接建立起来，使用的IP地址与之前的端口完全相同，现在建立的一个连接是之前连接的完全复用，我们还假定之前连接中有数据报残存在网络之中，这样的话现在的连接收到的数据有可能是之前连接的报文。为了防止这一点。TCP不允许新的连接复用time_wait状态下的socket。处于time_wait状态的socket在等待2MSL时间后，将会转为closed状态。这就意味着，一个成功建立的连接，必须使得之前网络中残余的数据报都丢失了。

:::

<font size=5>**CLOSE_WAIT**</font>

在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。


# TCP 挥手时出现大量 CLOSE_WAIT 或 TIME_WAIT 怎么解决？

<font size=5>**time_wait过多产生原因**</font>

正常的TCP客户端连接在关闭后，会进入一个TIME_WAIT的状态，持续的时间一般在1-4分钟，对于连接数不高的场景，1-4分钟其实并不长，对系统也不会有什么影响，但如果短时间内（例如1s内）进行大量的短连接，则可能出现这样一种情况：客户端所在的操作系统的socket端口和文件描述符被用尽，系统无法再发起新的连接！

举例来说：

假设每秒建立了1000个短连接（Web场景下是很常见的，例如每个请求都去访问memcached），假设TIME_WAIT的时间是1分钟，则1分钟内需要建立6W个短连接，由于TIME_WAIT时间是1分钟，这些短连接1分钟内都处于TIME_WAIT状态，都不会释放，而Linux默认的本地端口范围配置是：net.ipv4.ip_local_port_range = 32768 61000不到3W，因此这种情况下新的请求由于没有本地端口就不能建立了。

<font size=5>**time_wait过多解决方法**</font>

1.使用长连接来代替短连接；

2.修改ipv4.ip_local_port_range，增大可用端口范围，但只能缓解问题，不能根本解决问题；

::: tip ip_local_port_range：
表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。
:::

3.客户端程序中设置socket的SO_LINGER选项；

4.客户端机器打开tcp_tw_recycle和tcp_timestamps选项；

::: tip tcp_tw_recycle：
启用TIME-WAIT状态sockets的快速回收，这个选项不推荐启用。在NAT(Network Address Translation)网络下，会导致大量的TCP连接建立错误。
:::

5.客户端机器打开tcp_tw_reuse和tcp_timestamps选项；

::: tip tcp_tw_reuse：
tcp_tw_reuse=1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭。启用net.ipv4.tcp_tw_reuse后，如果新的时间戳，比以前存储的时间戳更大，那么linux将会从TIME-WAIT状态的存活连接中，选取一个，重新分配给新的连接出去的TCP连接。
:::

6.客户端机器设置tcp_max_tw_buckets为一个很小的值；

::: tip tcp_max_tw_buckets：
net.ipv4.tcp_max_tw_buckets = 5000，表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000。
:::


<font size=5>**close_wait过多原因**</font>

close_wait 按照正常操作的话应该很短暂的一个状态，接收到客户端的fin包并且回复客户端ack之后，会继续发送FIN包告知客户端关闭关闭连接，之后迁移到Last_ACK状态。但是close_wait过多只能说明没有迁移到Last_ACK，也就是服务端是否发送FIN包，只有发送FIN包才会发生迁移，所以问题定位在是否发送FIN包。FIN包的底层实现其实就是调用socket的close方法，**这里的问题出在没有执行close方法。说明服务端socket忙于读写。**

<font size=5>**close_wait过多的解决方案**</font>

1.代码层面做到

第一：使用完socket调用close方法；

第二：socket读控制，当读取的长度为0时（读到结尾），立即close；

第三：如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。如果不是AGAIN，立即close

2.可以设置TCP的连接时长keep_alive_time还有tcp监控连接的频率以及连接没有活动多长时间被迫断开连接


参考：

- [知乎文章](https://zhuanlan.zhihu.com/p/60382685)

- [线上大量CLOSE_WAIT原因深入分析](https://segmentfault.com/a/1190000017313251)

- [time_wait状态产生的原因，危害，如何避免](https://www.cnblogs.com/weiduoduo/p/11011891.html)

